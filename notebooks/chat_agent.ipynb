{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "The official Pinecone python package has been renamed from `pinecone-client` to `pinecone`. Please remove `pinecone-client` from your project dependencies and add `pinecone` instead. See the README at https://github.com/pinecone-io/pinecone-python-client for more information on using the python SDK.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpinecone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pinecone\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m speech, vision\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ixome/ixome/lib/python3.11/site-packages/pinecone/__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m.. include:: ../README.md\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe official Pinecone python package has been renamed from `pinecone-client` to `pinecone`. Please remove `pinecone-client` from your project dependencies and add `pinecone` instead. See the README at https://github.com/pinecone-io/pinecone-python-client for more information on using the python SDK.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mException\u001b[39m: The official Pinecone python package has been renamed from `pinecone-client` to `pinecone`. Please remove `pinecone-client` from your project dependencies and add `pinecone` instead. See the README at https://github.com/pinecone-io/pinecone-python-client for more information on using the python SDK."
     ]
    }
   ],
   "source": [
    "# notebooks/chat_agent.ipynb\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/vincent/ixome')\n",
    "from agents.chat_agent import ChatAgent\n",
    "import asyncio\n",
    "\n",
    "async def test():\n",
    "    agent = ChatAgent()\n",
    "    response = await agent.process_input(\"text\", \"My TV has no sound.\")\n",
    "    print(f\"Text Response: {response}\")\n",
    "\n",
    "asyncio.run(test())\n",
    "\n",
    "import logging\n",
    "from pinecone import Pinecone\n",
    "from google.cloud import speech, vision\n",
    "from langgraph.graph import Graph\n",
    "from typing import Dict, Any\n",
    "from core.config import PINECONE_API_KEY, GOOGLE_CREDENTIALS_PATH  # Assume config.py exists\n",
    "\n",
    "class ChatAgent:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "        self.logger.addHandler(handler)\n",
    "\n",
    "        # Initialize Pinecone\n",
    "        self.pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "        self.index = self.pc.Index(\"troubleshooter-index\")\n",
    "\n",
    "        # Initialize Google APIs\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_CREDENTIALS_PATH\n",
    "        self.speech_client = speech.SpeechClient()\n",
    "        self.vision_client = vision.ImageAnnotatorClient()\n",
    "\n",
    "        # Set up LangGraph\n",
    "        self.graph = Graph()\n",
    "        self.graph.add_node(\"input\", self.input_node)\n",
    "        self.graph.add_node(\"text_processing\", self.text_processing_node)\n",
    "        self.graph.add_node(\"voice_processing\", self.voice_processing_node)\n",
    "        self.graph.add_node(\"video_processing\", self.video_processing_node)\n",
    "        self.graph.add_node(\"issue_identification\", self.issue_identification_node)\n",
    "        self.graph.add_node(\"solution_retrieval\", self.solution_retrieval_node)\n",
    "        self.graph.add_node(\"response_generation\", self.response_generation_node)\n",
    "\n",
    "        self.graph.add_conditional_edges(\n",
    "            \"input\",\n",
    "            lambda state: state[\"input_type\"],\n",
    "            {\n",
    "                \"text\": \"text_processing\",\n",
    "                \"voice\": \"voice_processing\",\n",
    "                \"video\": \"video_processing\"\n",
    "            }\n",
    "        )\n",
    "        self.graph.add_edge(\"text_processing\", \"issue_identification\")\n",
    "        self.graph.add_edge(\"voice_processing\", \"issue_identification\")\n",
    "        self.graph.add_edge(\"video_processing\", \"issue_identification\")\n",
    "        self.graph.add_edge(\"issue_identification\", \"solution_retrieval\")\n",
    "        self.graph.add_edge(\"solution_retrieval\", \"response_generation\")\n",
    "        self.graph.set_entry_point(\"input\")\n",
    "        self.graph.set_finish_point(\"response_generation\")\n",
    "        self.app = self.graph.compile()\n",
    "\n",
    "    def input_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        self.logger.info(f\"Received input: type={state.get('input_type')}, data={state.get('input_data')}\")\n",
    "        return state\n",
    "\n",
    "    def text_processing_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state[\"processed_input\"] = state.get(\"input_data\", \"\")\n",
    "        self.logger.info(f\"Processed text input: {state['processed_input']}\")\n",
    "        return state\n",
    "\n",
    "    def voice_processing_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        audio_file = state.get(\"input_data\", \"\")\n",
    "        if audio_file and os.path.exists(audio_file):\n",
    "            try:\n",
    "                with open(audio_file, 'rb') as f:\n",
    "                    content = f.read()\n",
    "                audio = speech.RecognitionAudio(content=content)\n",
    "                config = speech.RecognitionConfig(\n",
    "                    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "                    sample_rate_hertz=16000,\n",
    "                    language_code='en-US'\n",
    "                )\n",
    "                response = self.speech_client.recognize(config=config, audio=audio)\n",
    "                for result in response.results:\n",
    "                    state[\"processed_input\"] = result.alternatives[0].transcript\n",
    "                    self.logger.info(f\"Processed voice input: {state['processed_input']}\")\n",
    "                    return state\n",
    "                state[\"processed_input\"] = \"No speech detected\"\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error processing voice: {e}\")\n",
    "                state[\"processed_input\"] = \"Error processing voice\"\n",
    "        else:\n",
    "            state[\"processed_input\"] = \"No audio file provided\"\n",
    "        return state\n",
    "\n",
    "    def video_processing_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        video_file = state.get(\"input_data\", \"\")\n",
    "        if video_file and os.path.exists(video_file):\n",
    "            try:\n",
    "                # Placeholder: Extract a frame or analyze video\n",
    "                # For now, treat as an image for compatibility with your code\n",
    "                with open(video_file, 'rb') as f:\n",
    "                    content = f.read()\n",
    "                image = vision.Image(content=content)  # Note: Needs video frame extraction\n",
    "                response = self.vision_client.label_detection(image=image)\n",
    "                labels = response.label_annotations\n",
    "                state[\"processed_input\"] = \", \".join([label.description for label in labels])\n",
    "                self.logger.info(f\"Processed video input: {state['processed_input']}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error processing video: {e}\")\n",
    "                state[\"processed_input\"] = \"Error processing video\"\n",
    "        else:\n",
    "            state[\"processed_input\"] = \"No video file provided\"\n",
    "        return state\n",
    "\n",
    "    def issue_identification_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        processed_input = state.get(\"processed_input\", \"\").lower()\n",
    "        self.logger.info(f\"Identifying issue from: {processed_input}\")\n",
    "        if \"no sound\" in processed_input:\n",
    "            state[\"issue\"] = \"no_sound\"\n",
    "        elif \"tv not turning on\" in processed_input:\n",
    "            state[\"issue\"] = \"tv_not_turning_on\"\n",
    "        elif \"settings\" in processed_input:\n",
    "            state[\"issue\"] = \"settings_issue\"\n",
    "        elif \"flashing light\" in processed_input or \"error code\" in processed_input:\n",
    "            state[\"issue\"] = \"error_code\"\n",
    "        else:\n",
    "            state[\"issue\"] = \"unknown\"\n",
    "        self.logger.info(f\"Identified issue: {state['issue']}\")\n",
    "        return state\n",
    "\n",
    "    def solution_retrieval_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Try Pinecone first\n",
    "        try:\n",
    "            query_vector = [0.1] * 1536  # Placeholder; replace with actual embedding\n",
    "            results = self.index.query(vector=query_vector, top_k=1, include_metadata=True)\n",
    "            if results['matches']:\n",
    "                state[\"solution\"] = results['matches'][0]['metadata'].get('solution', \"No solution found\")\n",
    "                self.logger.info(f\"Retrieved solution from Pinecone: {state['solution']}\")\n",
    "                return state\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Pinecone query failed: {e}\")\n",
    "\n",
    "        # Fallback to hardcoded solutions\n",
    "        solutions = {\n",
    "            \"no_sound\": \"Please check if the sound system is turned on and cables are connected.\",\n",
    "            \"tv_not_turning_on\": \"Please check the power cable and ensure the TV is plugged in.\",\n",
    "            \"settings_issue\": \"Navigate to the settings menu and verify the correct input source is selected.\",\n",
    "            \"error_code\": \"The flashing light indicates an error; please note the pattern and consult the device manual.\"\n",
    "        }\n",
    "        state[\"solution\"] = solutions.get(state[\"issue\"], \"Issue not recognized. Please provide more details.\")\n",
    "        self.logger.info(f\"Retrieved fallback solution: {state['solution']}\")\n",
    "        return state\n",
    "\n",
    "    def response_generation_node(self, state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        state[\"response\"] = state.get(\"solution\", \"No solution found.\")\n",
    "        self.logger.info(f\"Generated response: {state['response']}\")\n",
    "        return state\n",
    "\n",
    "    def process_input(self, input_type: str, input_data: str) -> str:\n",
    "        \"\"\"Main method to process user input and return a response.\"\"\"\n",
    "        state = {\"input_type\": input_type, \"input_data\": input_data}\n",
    "        result = self.app.invoke(state)\n",
    "        return result[\"response\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the agent locally\n",
    "    agent = ChatAgent()\n",
    "    # Test text input\n",
    "    response = agent.process_input(\"text\", \"My TV has no sound.\")\n",
    "    print(f\"Text Response: {response}\")\n",
    "    # Test voice input (requires a real audio file)\n",
    "    response = agent.process_input(\"voice\", \"/path/to/audio_file.wav\")\n",
    "    print(f\"Voice Response: {response}\")\n",
    "    # Test video input (requires a real video file)\n",
    "    response = agent.process_input(\"video\", \"/path/to/video_file.mp4\")\n",
    "    print(f\"Video Response: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ixome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
